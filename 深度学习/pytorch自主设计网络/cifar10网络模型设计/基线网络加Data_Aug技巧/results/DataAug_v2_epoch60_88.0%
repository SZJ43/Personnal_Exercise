transform_train = transforms.Compose(
    [
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomCrop(32, padding=4),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])

transform_test = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])
        
        self.fc1 = nn.Linear(512 * 3 * 3, 1280)
        self.fc2 = nn.Linear(1280, 10)

    def forward(self, x):
        # 第一个卷积块
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = self.maxpool(x)

        # 第二个卷积块
        x = F.relu(self.conv4(x))
        x = F.relu(self.conv5(x))
        x = F.relu(self.conv6(x))
        x = self.maxpool(x)

        # 第三个卷积块
        x = F.relu(self.conv7(x))
        x = F.relu(self.conv8(x))
        x = F.relu(self.conv9(x))
        x = self.maxpool(x)

        x = x.view(x.size(0), -1)

        x = self.fc1(x)
        x = self.fc2(x)

        return x





D:\Anaconda_v2\python.exe D:/pythonProject2/BaselineNetwork_addDataAug_v2.py 
D:\Anaconda_v2\lib\site-packages\torch\optim\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[0, 50000] loss: 11.5127
Accuracy of the network on the 500 train iterations: 17.000 %
epoch 0 cost 16.240234 sec
[1, 50000] loss: 10.0554
Accuracy of the network on the 500 train iterations: 28.000 %
epoch 1 cost 13.927303 sec
[2, 50000] loss: 8.6520
Accuracy of the network on the 500 train iterations: 50.000 %
epoch 2 cost 15.508667 sec
[3, 50000] loss: 7.6775
Accuracy of the network on the 500 train iterations: 47.000 %
epoch 3 cost 14.653289 sec
[4, 50000] loss: 6.8497
Accuracy of the network on the 500 train iterations: 56.000 %
epoch 4 cost 15.265939 sec
[5, 50000] loss: 5.9589
Accuracy of the network on the 500 train iterations: 61.000 %
epoch 5 cost 13.301094 sec
[6, 50000] loss: 5.1728
Accuracy of the network on the 500 train iterations: 69.000 %
epoch 6 cost 13.262534 sec
[7, 50000] loss: 4.5514
Accuracy of the network on the 500 train iterations: 69.000 %
epoch 7 cost 13.297404 sec
[8, 50000] loss: 4.0412
Accuracy of the network on the 500 train iterations: 79.000 %
epoch 8 cost 13.326444 sec
[9, 50000] loss: 3.6545
Accuracy of the network on the 500 train iterations: 75.000 %
epoch 9 cost 13.425643 sec
[10, 50000] loss: 3.3534
Accuracy of the network on the 500 train iterations: 82.000 %
epoch 10 cost 13.442176 sec
[11, 50000] loss: 3.0026
Accuracy of the network on the 500 train iterations: 81.000 %
epoch 11 cost 13.358346 sec
[12, 50000] loss: 2.7766
Accuracy of the network on the 500 train iterations: 76.000 %
epoch 12 cost 13.397367 sec
[13, 50000] loss: 2.5430
Accuracy of the network on the 500 train iterations: 79.000 %
epoch 13 cost 13.433619 sec
[14, 50000] loss: 2.3667
Accuracy of the network on the 500 train iterations: 83.000 %
epoch 14 cost 13.418072 sec
[15, 50000] loss: 2.2036
Accuracy of the network on the 500 train iterations: 86.000 %
epoch 15 cost 13.363665 sec
[16, 50000] loss: 1.9972
Accuracy of the network on the 500 train iterations: 89.000 %
epoch 16 cost 13.411937 sec
[17, 50000] loss: 1.9140
Accuracy of the network on the 500 train iterations: 80.000 %
epoch 17 cost 13.449114 sec
[18, 50000] loss: 1.7715
Accuracy of the network on the 500 train iterations: 87.000 %
epoch 18 cost 13.406712 sec
[19, 50000] loss: 1.6291
Accuracy of the network on the 500 train iterations: 84.000 %
epoch 19 cost 13.429926 sec
[20, 50000] loss: 1.5406
Accuracy of the network on the 500 train iterations: 88.000 %
epoch 20 cost 13.415703 sec
[21, 50000] loss: 1.4290
Accuracy of the network on the 500 train iterations: 86.000 %
epoch 21 cost 13.487422 sec
[22, 50000] loss: 1.3372
Accuracy of the network on the 500 train iterations: 92.000 %
epoch 22 cost 13.467571 sec
[23, 50000] loss: 1.2474
Accuracy of the network on the 500 train iterations: 87.000 %
epoch 23 cost 13.470673 sec
[24, 50000] loss: 1.1543
Accuracy of the network on the 500 train iterations: 88.000 %
epoch 24 cost 13.384491 sec
[25, 50000] loss: 1.0949
Accuracy of the network on the 500 train iterations: 94.000 %
epoch 25 cost 13.393641 sec
[26, 50000] loss: 0.9792
Accuracy of the network on the 500 train iterations: 91.000 %
epoch 26 cost 13.375848 sec
[27, 50000] loss: 0.9652
Accuracy of the network on the 500 train iterations: 91.000 %
epoch 27 cost 13.392580 sec
[28, 50000] loss: 0.8906
Accuracy of the network on the 500 train iterations: 90.000 %
epoch 28 cost 13.415713 sec
[29, 50000] loss: 0.8080
Accuracy of the network on the 500 train iterations: 95.000 %
epoch 29 cost 13.441709 sec
[30, 50000] loss: 0.7547
Accuracy of the network on the 500 train iterations: 98.000 %
epoch 30 cost 13.447805 sec
[31, 50000] loss: 0.7036
Accuracy of the network on the 500 train iterations: 94.000 %
epoch 31 cost 13.449429 sec
[32, 50000] loss: 0.6740
Accuracy of the network on the 500 train iterations: 95.000 %
epoch 32 cost 13.756364 sec
[33, 50000] loss: 0.5869
Accuracy of the network on the 500 train iterations: 95.000 %
epoch 33 cost 13.548000 sec
[34, 50000] loss: 0.5651
Accuracy of the network on the 500 train iterations: 98.000 %
epoch 34 cost 13.616628 sec
[35, 50000] loss: 0.5277
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 35 cost 13.775407 sec
[36, 50000] loss: 0.5055
Accuracy of the network on the 500 train iterations: 98.000 %
epoch 36 cost 13.839246 sec
[37, 50000] loss: 0.4615
Accuracy of the network on the 500 train iterations: 95.000 %
epoch 37 cost 14.296927 sec
[38, 50000] loss: 0.4386
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 38 cost 13.743691 sec
[39, 50000] loss: 0.4032
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 39 cost 13.628611 sec
[40, 50000] loss: 0.3816
Accuracy of the network on the 500 train iterations: 99.000 %
epoch 40 cost 13.738453 sec
[41, 50000] loss: 0.3473
Accuracy of the network on the 500 train iterations: 98.000 %
epoch 41 cost 13.880318 sec
[42, 50000] loss: 0.3139
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 42 cost 13.635065 sec
[43, 50000] loss: 0.3214
Accuracy of the network on the 500 train iterations: 98.000 %
epoch 43 cost 13.403323 sec
[44, 50000] loss: 0.2938
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 44 cost 13.655886 sec
Finished Training
Accuracy of the network on the 10000 test images: 88.150 %

进程已结束,退出代码0
