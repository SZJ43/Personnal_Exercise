        self.fc1 = nn.Linear(512 * 3 * 3, 1280)
        self.fc2 = nn.Linear(1280, 10)

    def forward(self, x):
        # 第一个卷积块
        x = self.bn32(F.relu(self.conv1(x)))
        x = self.bn64(F.relu(self.conv2(x)))
        x = self.bn64(F.relu(self.conv3(x)))
        x = self.maxpool(x)

        # 第二个卷积块
        x = self.bn128(F.relu(self.conv4(x)))
        x = self.bn128(F.relu(self.conv5(x)))
        x = self.bn256(F.relu(self.conv6(x)))
        x = self.maxpool(x)

        # 第三个卷积块
        x = self.bn256(F.relu(self.conv7(x)))
        x = self.bn512(F.relu(self.conv8(x)))
        x = self.bn512(F.relu(self.conv9(x)))
        x = self.maxpool(x)

        x = x.view(x.size(0), -1)

        x = self.fc1(x)
        x = self.fc2(x)

        return x
        
        D:\Anaconda_v2\python.exe D:/pythonProject2/BaselineNetwork_add_BN_v2.py 
D:\Anaconda_v2\lib\site-packages\torch\optim\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[0, 50000] loss: 6.2945
Accuracy of the network on the 500 train iterations: 68.000 %
epoch 0 cost 17.193330 sec
[1, 50000] loss: 3.7644
Accuracy of the network on the 500 train iterations: 74.000 %
epoch 1 cost 15.118097 sec
[2, 50000] loss: 2.7303
Accuracy of the network on the 500 train iterations: 82.000 %
epoch 2 cost 15.181541 sec
[3, 50000] loss: 2.0788
Accuracy of the network on the 500 train iterations: 87.000 %
epoch 3 cost 14.912637 sec
[4, 50000] loss: 1.5316
Accuracy of the network on the 500 train iterations: 84.000 %
epoch 4 cost 14.746767 sec
[5, 50000] loss: 1.0542
Accuracy of the network on the 500 train iterations: 91.000 %
epoch 5 cost 14.444827 sec
[6, 50000] loss: 0.7623
Accuracy of the network on the 500 train iterations: 89.000 %
epoch 6 cost 14.953041 sec
[7, 50000] loss: 0.4958
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 7 cost 14.857048 sec
[8, 50000] loss: 0.3334
Accuracy of the network on the 500 train iterations: 97.000 %
epoch 8 cost 15.225318 sec
[9, 50000] loss: 0.3246
Accuracy of the network on the 500 train iterations: 99.000 %
epoch 9 cost 20.179411 sec
[10, 50000] loss: 0.2429
Accuracy of the network on the 500 train iterations: 99.000 %
epoch 10 cost 21.070138 sec
[11, 50000] loss: 0.1517
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 11 cost 20.986062 sec
[12, 50000] loss: 0.1228
Accuracy of the network on the 500 train iterations: 98.000 %
epoch 12 cost 21.176775 sec
[13, 50000] loss: 0.0509
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 13 cost 21.376202 sec
[14, 50000] loss: 0.0344
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 14 cost 21.218978 sec
[15, 50000] loss: 0.0229
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 15 cost 21.212046 sec
[16, 50000] loss: 0.0062
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 16 cost 20.940013 sec
[17, 50000] loss: 0.0014
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 17 cost 21.290850 sec
[18, 50000] loss: 0.0007
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 18 cost 21.067541 sec
[19, 50000] loss: 0.0004
Accuracy of the network on the 500 train iterations: 100.000 %
epoch 19 cost 21.057790 sec
Finished Training
Accuracy of the network on the 10000 test images: 86.680 %

进程已结束,退出代码0
